研究目標：
==
 #### ✔建立一個能夠識別不同種類花卉的深度學習模型。模型應該能夠處理彩色圖片輸入，並對每種花卉產生一個預測標籤。<br>
 #### ✔評估模型的性能。使用準確度指標來評估模型的預測能力。<br>
 #### ✔優化模型的性能。通過調整模型參數、使用不同的模型結構、應用數據增強等方法來提高模型的預測準確度。<br>
 #### ✔應用模型於實際問題。探討如何將該模型應用於實際的花卉識別問題，例如建立一個手機應用程式，用戶可以通過拍攝花卉照片來識別花卉種類。<br>

<br>

整體步驟 :
==
### 一. 資料預處理：
> 1.  圖像大小縮放：將所有圖像調整到相同的尺寸，因為神經網路需要固定大小的輸入。
> 2.  像素值轉換：也可視為標準化，將像素值從0-255的整數轉換為0-1之間的浮點數，這有助於模型的訓練。
> 3.  資料分割：將資料分割為訓練集和測試集，訓練集用於訓練模型，測試集用於評估模型的性能。
> 4.  標籤編碼：將分類標籤進行獨熱編碼(One-Hot Encoding)，轉換為模型可以處理的格式。

### 二. 建立模型：
> 1.  定義模型結構：使用Keras定義模型的結構，包括卷積層、池化層和全連接層。
> 2.  設定優化器：選擇一種優化器，如SGD或Adam，用於在訓練過程中更新模型的權重。
> 3.  設定損失函數：選擇一種損失函數，如交叉熵，用於在訓練過程中評估模型的性能。
> 4.  設定評估指標：選擇一種或多種評估指標，如準確率，用於在訓練過程中監控模型的性能。

### 三. 訓練模型：
> 1.  設定訓練參數：設定訓練的週期數（epochs）和批次大小（batch size）。
> 2.  進行訓練：將預處理過的訓練資料餵入模型進行訓練。

### 四. 評估模型：
> 1.  繪製訓練曲線：使用matplotlib繪製訓練過程中的損失和準確率曲線。
> 2.  評估測試集性能：使用測試集資料評估模型的性能。

### 五. 預測與視覺化：
> 1.  進行預測：使用訓練好的模型對測試集進行預測。
> 2.  視覺化預測結果：找出模型預測正確和錯誤的樣本，並將這些樣本的圖像和預測結果進行視覺化。

### 六. 模型預測與評估報告：
> 1.  進行預測：使用訓練好的模型對測試集進行預測。這將產生一個包含每個類別預測概率的數組。
> 2.  轉換預測結果：將預測結果轉換為類別標籤。這是通過選擇每個樣本的預測概率最高的類別來完成的。
> 3.  轉換真實標籤：將真實標籤也轉換為類別標籤。這是因為我們的標籤是獨熱編碼的，我們需要將它們轉換回原始的類別標籤，以便與預測標籤進行比較。
> 4.  計算評估指標：使用sklearn的classification_report函數計算每個類別的精確度、召回率和F1分數，並打印出來。這些指標可以幫助我們更好地理解模型在每個類別上的性能。

<br>

重點技術 :
==
  * >卷積神經網路（CNN）：<br>CNN是一種深度學習模型，專門用於處理具有網格結構的數據（如圖像）。CNN的主要組成部分是卷積層和池化層。卷積層透過卷積運算來學習輸入數據的局部特徵，而池化層則用於降低數據的維度，減少計算量並防止過擬合。在這些層之後，通常會接上一個或多個全連接層來進行分類或回歸。

  * >ReLU激活函數：ReLU是一種常用的激活函數，其數學表達式為f(x)=max(0,x)。也就是說，對於負輸入值，ReLU會輸出0；對於正輸入值，ReLU會直接輸出該值。ReLU激活函數的優點是計算簡單且不容易產生梯度消失問題，因此在深度學習中被廣泛使用。

  * >Softmax激活函數：Softmax函數可以將一組數字轉換為概率分佈。給定一組輸入x1, x2, ..., xn，Softmax函數會計算每個輸入的指數，然後將每個指數除以所有指數的總和，得到每個輸入的概率。Softmax函數常用於多類別分類問題的輸出層，輸出每個類別的概率。

  * >學習率衰減（Learning Rate Decay）：學習率是一個控制模型學習速度的超參數。如果學習率太大，模型可能會在最優解附近震盪而無法收斂；如果學習率太小，模型的學習速度可能會非常慢。學習率衰減是一種動態調整學習率的策略，通常在訓練過程中逐漸降低學習率，以幫助模型收斂到更好的解。

  * >數據增強（Data Augmentation）：數據增強是一種防止過擬合的技術，通過對訓練數據進行隨機變換來擴增數據集。常見的數據增強方法包括圖像旋轉、縮放、平移、翻轉等。透過數據增強，模型可以學習到更多的數據變化，從而提高其泛化能力。

  * >批次訓練（Batch Training）：在深度學習中，我們通常會將訓練數據分成多個小批次（batch），然後在每次訓練迭代中，模型會同時處理一個批次的數據。批次訓練可以加快訓練速度，因為模型可以同時處理多個樣本的計算；此外，批次訓練還可以提高模型的泛化能力，因為每次更新的方向是基於一個批次的數據，而不是單個樣本。

  * >獨熱編碼（One-Hot Encoding）：是一種將類別型數據轉換為數值型數據的方法，尤其適用於處理無序的類別型數據。它將每個類別轉換為一個唯一的二元向量：對於n個類別，每個類別都會被轉換為一個長度為n的向量，其中只有一個元素為1（表示該類別），其餘元素都為0。這種方法可以避免模型誤解類別間的數值關係，但可能會導致數據維度的增加。

<br>

結論分析 :
==
<img src="https://github.com/AlanChou0330/Analyzing-Flower-Types/blob/master/conclusion.png" width="550"/>

<br>

### 參數解釋 :<br>
  * > 1.  Precision（精確度）：是模型預測為正的樣本中，實際也為正的比例。計算公式為：TP / (TP + FP)，其中TP是真正例（模型預測為正，實際也為正的樣本數），FP是假正例（模型預測為正，實際為負的樣本數）。
  * > 2.  Recall（召回率）：也被稱為敏感度或真陽性率，是所有實際為正的樣本中，被模型正確預測為正的比例。計算公式為：TP / (TP + FN)，其中FN是假負例（模型預測為負，實際為正的樣本數）。
  * > 3.  F1-score：是精確度和召回率的調和平均數，可以在兩者之間取得平衡。F1-score的最大值為1，表示模型的精確度和召回率都很高。計算公式為：2 * (Precision * Recall) / (Precision + Recall)。
  * > 4.  Support：是每個類別在數據集中的實際出現次數。
  * > 5.  Accuracy（準確度）：是模型正確預測的樣本數（無論是正樣本還是負樣本）與所有樣本數的比例。計算公式為：(TP + TN) / (TP + TN + FP + FN)，其中TN是真負例（模型預測為負，實際也為負的樣本數）。
  * > 6.  Macro avg：是對所有類別的指標值（例如精確度、召回率或F1-score）進行簡單平均得到的。
  * > 7.  Weighted avg：是對所有類別的指標值進行加權平均得到的，加權的依據是每個類別的support。

<br>

### 在本研究中，我們成功地開發了一種深度學習模型，用於識別五種不同的花卉類型：雛菊、向日葵、鬱金香、蒲公英和玫瑰。該模型在獨立測試集上的整體準確度達到了92%。<br>
1. 雛菊 (Daisy)
   - 準確度：93%
   - 召回率：93%

2. 向日葵 (Sunflower)
   - 準確度：95%
   - 召回率：93%

3. 鬱金香 (Tulip)
   - 準確度：92%
   - 召回率：85%

4. 蒲公英 (Dandelion)
   - 準確度：95%
   - 召回率：99%

5. 玫瑰 (Rose)
   - 準確度：88%
   - 召回率：94%

<br>

### 這些結果證明了模型在識別這五種花卉上的有效性，並且在各個類別上都達到了相對高的準確度和召回率。未來的研究將集中在進一步優化模型性能，並擴展其識別能力至更多種類的花卉。

<br><br>

## 資料數據集來源 :

<https://www.kaggle.com/datasets/alxmamaev/flowers-recognition>

